Back to [Projects List](../../README.md#ProjectsList)

# Low-Cost Ultrasound Training

## Key Investigators

- David García Mato (Ebatinca S.L., Las Palmas de Gran Canaria, Spain)
- Csaba Pinter (Ebatinca S.L., Las Palmas de Gran Canaria, Spain)
- Rebecca Hisey (Queen’s University, Kingston, ON, Canada)
- Matthew Holden (Carleton University, Ottawa, ON, Canada)

# Project Description
[**Ebatinca S.L.**](https://ebatinca.com/) is currently developing a **low-cost training platform for ultrasound imaging and ultrasound-guided procedures** in low- and middle-income countries. We are developing a 3D Slicer based application to perform training exercises and evaluate participants. The app is called [**TrainUS**](https://github.com/EBATINCA/TrainUS) and it is available with open-source license.

Some basic features have already been developed: participant/recording management, hardware connection, selection of training exercises,...

Currently, we are working on the development of basic exercises to train basic ultrasound skills. The app should be able to evaluate recordings made by users and to provide feedback about their performance. 

## Objective

<!-- Describe here WHAT you would like to achieve (what you will have as end result). -->

1. Develop basic module to train in-plane and out-of-plane needle insertions.
2. Manage recordings (sequences) by saving/loading .sqbr files.
3. Show exercise instructions using images and videos displayed in the module.
4. Use [PerkTutor extension](http://perktutor.github.io/) to evaluate recordings and get overall metrics (elapsed time, needle path length, rotations, translations,...). Display table to users showing metric values.
5. Enable the computation of metrics for each sample in the recording (distance from needle tip to US plane, distance to target,...) and visualize metric values along the recording time. Show plots to users during recording playback.
6. Test exercise with hardware (US, tracker, phantom,...)
7. Integrate exercise in TrainUS app
8. Record insertion data for experts and novices and use [PerkTutor extension](http://perktutor.github.io/) to provide specific feedback to users about their performance.
9. Determine best way to integrate video-based metrics into PerkTutor.

## Approach and Plan

<!-- Describe here HOW you would like to achieve the objectives stated above. -->

1. Describe specific steps of **what you plan to do** to achieve the above described objectives.
1. ...
1. ...

## Progress and Next Steps

<!-- Update this section as you make progress, describing of what you have ACTUALLY DONE. If there are specific steps that you could not complete then you can describe them here, too. -->

1. Describe specific steps you **have actually done**.
1. ...
1. ...

# Illustrations
<img src="https://user-images.githubusercontent.com/10816661/172382966-725defb3-6729-4c5e-856d-2e4d9fb5653c.JPG" alt="drawing" width="800"/>

<!-- Add pictures and links to videos that demonstrate what has been accomplished.
![Description of picture](Example2.jpg)
![Some more images](Example2.jpg)
-->

# Background and References
- Previous [Low-Cost Ultrasound Tracking](https://github.com/NA-MIC/ProjectWeek/blob/master/PW36_2022_Virtual/Projects/LowCostUltrasoundTraining/README.md) during 36th Project Week held virtually on January 17-21, 2022.
- **TrainUS** GitHub repository: [TrainUs app](https://github.com/EBATINCA/TrainUS)
- **PerkTutor** GitHub repository: [PerkTutor extension](https://github.com/PerkTutor/PerkTutor)

<!-- If you developed any software, include link to the source code repository. If possible, also add links to sample data, and to any relevant publications. -->
